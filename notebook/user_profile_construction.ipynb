{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6dcabe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9315d2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Load original data (if needed again)\n",
    "column_names = ['id', 'category', 'subcategory', 'title', 'abstract', 'url', 'entities', 'events']\n",
    "df = pd.read_csv(r'C:\\Users\\Admin\\Downloads\\archive\\news.tsv\\news.tsv', sep='\\t', names=column_names, header=None)\n",
    "df['content'] = df['title'].fillna('') + ' ' + df['abstract'].fillna('')\n",
    "\n",
    "# Load clean text (if continuing from last notebook)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\W+', ' ', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    tokens = text.split()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['clean_content'] = df['content'].apply(preprocess_text)\n",
    "\n",
    "# TF-IDF transformation\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "tfidf_matrix = tfidf.fit_transform(df['clean_content'])\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebec6f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Should NFL be able to fine players for critici...</td>\n",
       "      <td>Several fines came down against NFL players fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Elijah Cummings to lie in state at US Capitol ...</td>\n",
       "      <td>Cummings, a Democrat whose district included s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>40+ Stuffed Pasta Recipes You'll Want To Make ...</td>\n",
       "      <td>Stuff yourself.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "5   Should NFL be able to fine players for critici...   \n",
       "20  Elijah Cummings to lie in state at US Capitol ...   \n",
       "50  40+ Stuffed Pasta Recipes You'll Want To Make ...   \n",
       "\n",
       "                                             abstract  \n",
       "5   Several fines came down against NFL players fo...  \n",
       "20  Cummings, a Democrat whose district included s...  \n",
       "50                                    Stuff yourself.  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's simulate a user liking 3 articles by index\n",
    "liked_article_indices = [5, 20, 50]  # change these to real IDs if needed\n",
    "\n",
    "# Show the liked articles\n",
    "df.iloc[liked_article_indices][['title', 'abstract']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92bf3884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get TF-IDF vectors of liked articles\n",
    "user_profile_matrix = tfidf_df.iloc[liked_article_indices]\n",
    "\n",
    "# Average them to form the user profile\n",
    "user_profile_vector = user_profile_matrix.mean(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "553b0778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top interests of the user:\n",
      "officiating    0.189334\n",
      "pasta          0.169911\n",
      "cummings       0.165341\n",
      "stuff          0.164510\n",
      "fine           0.158006\n",
      "recipe         0.130729\n",
      "nfl            0.112462\n",
      "player         0.110428\n",
      "every          0.109456\n",
      "want           0.103147\n",
      "lie            0.090949\n",
      "make           0.089678\n",
      "night          0.086172\n",
      "section        0.083946\n",
      "elijah         0.083049\n",
      "capitol        0.082215\n",
      "week           0.081791\n",
      "included       0.080784\n",
      "whose          0.074864\n",
      "age            0.071907\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Show top terms in the user profile vector\n",
    "top_terms = user_profile_vector.sort_values(ascending=False).head(20)\n",
    "print(\"Top interests of the user:\")\n",
    "print(top_terms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48a4171",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
